{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse, scipy.io, scipy.optimize\n",
    "from scipy.special import expit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a', # Color blind color cycle\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=CB_color_cycle) \n",
    "\n",
    "clip_01 = lambda M : np.clip(M, a_min=0, a_max=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells to load the networks. We use Cora as an example here. Note that preprocessing is not necessary for Cora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adj = sp.io.loadmat('cora.mat')['network']\n",
    "\n",
    "# destroy diagonal and binarize\n",
    "# adj.setdiag(0)\n",
    "# adj.data = 1. * (adj.data > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LPCA loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lpca_loss(factors, adj_s, rank): # adj_s = shifted adj with -1's and +1's\n",
    "    n_row, n_col = adj_s.shape\n",
    "    U = factors[:n_row*rank].reshape(n_row, rank)\n",
    "    V = factors[n_row*rank:].reshape(rank, n_col)\n",
    "    logits = U @ V\n",
    "    prob_wrong = expit(-logits * adj_s)\n",
    "    loss = (np.logaddexp(0,-logits*adj_s)).sum()# / n_element    \n",
    "    U_grad = -(prob_wrong * adj_s) @ V.T# / n_element\n",
    "    V_grad = -U.T @ (prob_wrong * adj_s)# / n_element\n",
    "    print(loss)\n",
    "    return loss, np.concatenate((U_grad.flatten(), V_grad.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the embeddings (factors) and set a callback function; then, optimize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rank = 128\n",
    "save_interval = 10 # the number of iterations after which to save the embeddings\n",
    "factor_file_path = 'cora_embed.mat'\n",
    "\n",
    "n_row, n_col = adj.shape\n",
    "factors = -1+2*np.random.random(size=(np.sum(adj.shape)*rank)) # initalize uniformly on [-1,+1]\n",
    "iter_num = 0\n",
    "def callback_recm(x_i): # prints the loss and periodically saves the factors\n",
    "    global iter_num\n",
    "    iter_num += 1\n",
    "    if iter_num % save_interval == 0:\n",
    "        global factors, n_row, n_col, rank\n",
    "        factors = x_i\n",
    "        U = factors[:n_row*rank].reshape(n_row, rank)\n",
    "        V = factors[n_row*rank:].reshape(rank, n_col)\n",
    "        frob_error_norm = np.linalg.norm(clip_01(U@V) - adj) / sp.sparse.linalg.norm(adj)\n",
    "        print(iter_num, \"Frob_error_norm: \", frob_error_norm)\n",
    "#         data = {'U':U, 'V':V}\n",
    "#         scipy.io.savemat(factor_file_path, data)\n",
    "\n",
    "U = factors[:n_row*rank].reshape(n_row, rank)\n",
    "V = factors[n_row*rank:].reshape(rank, n_col)\n",
    "frob_error_norm = np.linalg.norm(1.*(U @ V > 0) - adj) / sp.sparse.linalg.norm(adj)\n",
    "print(frob_error_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = scipy.optimize.minimize(lpca_loss, x0=factors, \n",
    "                              args=(-1 + 2*np.array(adj.todense()), rank), jac=True, method='L-BFGS-B', \n",
    "                              callback=callback_recm, \n",
    "                              options={'maxiter':2000}\n",
    "                             )\n",
    "factors = res.x\n",
    "U = res.x[:n_row*rank].reshape(n_row, rank)\n",
    "V = res.x[n_row*rank:].reshape(rank, n_col)\n",
    "frob_error_norm = np.linalg.norm(clip_01(U@V) - adj) / sp.sparse.linalg.norm(adj)\n",
    "print(\"Frob norm error: \", frob_error_norm)\n",
    "# data = {'U':U, 'V':V}\n",
    "# scipy.io.savemat(factor_file_path, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells for comparison to TSVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate a rank k TSVD factorization of a small sparse matrix adj\n",
    "def factor_TSVD(adj, k):\n",
    "    w, v = np.linalg.eigh(np.array(adj.todense()))\n",
    "    order = np.argsort(np.abs(w))[::-1]\n",
    "    w = w[order[:k]]\n",
    "    v = v[:,order[:k]]\n",
    "    U_tsvd, V_tsvd = v * np.sqrt(np.abs(w))[None,:], (np.sign(w)*np.sqrt(np.abs(w)))[:,None] * v.T\n",
    "    return U_tsvd, V_tsvd\n",
    "U_tsvd, V_tsvd = factor_TSVD(adj, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the Frobenius errors of the LPCA and TSVD reconstructions, respectively \n",
    "print( np.linalg.norm(adj.todense() - expit(U@V)) / sp.sparse.linalg.norm(adj) )\n",
    "print( np.linalg.norm(adj.todense() - clip_01(U_tsvd@V_tsvd)) / sp.sparse.linalg.norm(adj) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code for other experiments:\n",
    "A cell to create the triangle-dense toy graph from the paper, then a cell to plot reconstructions given embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the toy graph with n_tri triangles\n",
    "def tri_path(n_tri, cycle=True, self_loops=True):\n",
    "    tri_block = sp.sparse.coo_matrix([[0,1,1],[1,0,1],[1,1,0]])\n",
    "    mat = sp.sparse.block_diag((tri_block,)*n_tri)\n",
    "    diag = np.tile([0,0,1], n_tri)[:-1]\n",
    "    mat += sp.sparse.diags([diag, diag], [-1,1])\n",
    "    if cycle:\n",
    "        mat[0,-1] = 1\n",
    "        mat[-1,0] = 1\n",
    "    if self_loops:\n",
    "        mat += sp.sparse.identity(n_tri*3)\n",
    "    return mat\n",
    "adj = tri_path(100, cycle=True, self_loops=True)\n",
    "plt.matshow(adj.todense()[:12,:][:,:12])\n",
    "plt.matshow(adj.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3)\n",
    "fig.set_size_inches(6.5,3)\n",
    "fig.set_dpi(300)\n",
    "\n",
    "im = axs[0,0].imshow(adj[:12,:][:,:12].todense(), vmin=0,vmax=1)\n",
    "axs[0,0].set_axis_off()\n",
    "axs[1,0].imshow(adj.todense(), vmin=0,vmax=1)\n",
    "axs[1,0].set_axis_off()\n",
    "axs[0,0].set_title('True')\n",
    "\n",
    "axs[0,1].imshow(expit(U@V)[:12,:][:,:12], vmin=0,vmax=1)\n",
    "axs[0,1].set_axis_off()\n",
    "axs[1,1].imshow(expit(U@V), vmin=0,vmax=1)\n",
    "axs[1,1].set_axis_off()\n",
    "axs[0,1].set_title('LPCA ' + str(rank))\n",
    "\n",
    "axs[0,2].imshow(np.clip(U_tsvd@V_tsvd, a_min=0, a_max=1)[:12,:][:,:12], vmin=0,vmax=1)\n",
    "axs[0,2].set_axis_off()\n",
    "axs[1,2].imshow(np.clip(U_tsvd@V_tsvd, a_min=0, a_max=1), vmin=0,vmax=1)\n",
    "axs[1,2].set_axis_off()\n",
    "axs[0,2].set_title('TSVD ' + str(rank))\n",
    "\n",
    "fig.colorbar(im, ax=axs.ravel().tolist(), ticks=[0, 0.5, 1], shrink=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cell to calculate triangles in induced subgraphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "n = adj.shape[0]\n",
    "skip_int = 100 # collect data for every 10th point in the plot\n",
    "\n",
    "adj_recon_lpca = expit(U@V)\n",
    "deg_recon_lpca = np.array(adj_recon_lpca.sum(axis=1)).flatten()\n",
    "deg_order_lpca = np.argsort(deg_recon_lpca)\n",
    "deg_seq_recon_lpca = deg_recon[deg_order[::-skip_int]]\n",
    "\n",
    "adj_recon_sort = np.copy(adj_recon_lpca[np.ix_(deg_order_lpca, deg_order_lpca)])\n",
    "\n",
    "def get_num_tri(i):\n",
    "    global adj_recon_sort\n",
    "    sub_adj = adj_recon_sort[:i+1,:i+1]\n",
    "    num_tri = (1. * sub_adj @ sub_adj @ sub_adj).diagonal().sum() / 6\n",
    "    return num_tri\n",
    "\n",
    "pool = Pool(5)\n",
    "tri_seq_recon_lpca = np.array(pool.map(get_num_tri, np.arange(n)[::-skip_int]))\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adj_recon_tsvd = np.clip(U_tsvd@V_tsvd, a_min=0, a_max=1)\n",
    "deg_recon_tsvd = np.array(adj_recon_tsvd.sum(axis=1)).flatten()\n",
    "deg_order_tsvd = np.argsort(deg_recon_tsvd)\n",
    "deg_seq_recon_tsvd = deg_recon_tsvd[deg_order_tsvd[::-skip_int]]\n",
    "\n",
    "adj_recon_sort = np.copy(adj_recon_tsvd[np.ix_(deg_order_tsvd, deg_order_tsvd)])\n",
    "\n",
    "pool = Pool(5)\n",
    "tri_seq_recon_tsvd = np.array(pool.map(get_num_tri, np.arange(n)[::-skip_int]))\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deg_true = np.array(adj.sum(axis=1)).flatten()\n",
    "deg_order_true = np.argsort(deg_true)\n",
    "deg_seq_true = deg_recon[deg_order[::-skip_int]]\n",
    "\n",
    "adj_recon_sort = np.copy(adj.todense()[np.ix_(deg_order_true, deg_order_true)])\n",
    "\n",
    "pool = Pool(5)\n",
    "tri_seq_true = np.array(pool.map(get_num_tri, np.arange(adj.shape[0])[::-skip_int]))\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(deg_seq_recon_lpca, tri_seq_recon_lpca / n, label='LPCA')\n",
    "ax.semilogy(deg_seq_recon_tsvd, tri_seq_recon_tsvd / n, label='TSVD')\n",
    "ax.semilogy(deg_seq_true, tri_seq_true / n, label='True', linestyle='--')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.autoscale(enable=True, axis='x', tight=True)\n",
    "ax.autoscale(enable=True, axis='y', tight=True)\n",
    "ax.set_xlim(1,)\n",
    "ax.set_ylim(1/n,)\n",
    "\n",
    "ax.set_ylabel('Triangles per Node')\n",
    "ax.set_xlabel('Degree Upper Bound')\n",
    "\n",
    "fig.set_dpi(300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
